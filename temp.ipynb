{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80c4dc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22ê°œì˜ íŒŒì¼ì´ 'docs/train_chunks'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# CSV íŒŒì¼ ê²½ë¡œ (ì§ì ‘ ê²½ë¡œë¡œ ë°”ê¿”ì£¼ì„¸ìš”)\n",
    "csv_path = \"data/test_with_answer.csv\"\n",
    "\n",
    "# ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "output_dir = \"docs/train_chunks\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ëª‡ í–‰ì”© ë‚˜ëˆŒ ê²ƒì¸ì§€ ì„¤ì •\n",
    "chunk_size = 500  # í•„ìš”ì— ë”°ë¼ 100, 1000 ë“±ìœ¼ë¡œ ì¡°ì • ê°€ëŠ¥\n",
    "\n",
    "# CSV ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ì´ ë¶„í•  ìˆ˜ ê³„ì‚°\n",
    "num_chunks = (len(df) + chunk_size - 1) // chunk_size\n",
    "\n",
    "# ê° ë¶„í• ì„ í…ìŠ¤íŠ¸ë¡œ ì €ì¥\n",
    "for i in range(num_chunks):\n",
    "    chunk = df.iloc[i * chunk_size : (i + 1) * chunk_size]\n",
    "    lines = []\n",
    "    for _, row in chunk.iterrows():\n",
    "        err = row.get(\"err_sentence\", \"\")\n",
    "        cor = row.get(\"cor_sentence\", \"\")\n",
    "        if pd.notnull(err) and pd.notnull(cor):\n",
    "            lines.append(f\"ì…ë ¥: {err}\\nì¶œë ¥: {cor}\\n\")\n",
    "\n",
    "    file_path = os.path.join(output_dir, f\"train_chunk_{i+1:02}.txt\")\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "print(f\"{num_chunks}ê°œì˜ íŒŒì¼ì´ '{output_dir}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae004020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” ì „ì²´ ì§„í–‰ ìƒí™©: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [25:00<00:00, 13.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š [base_02] í‰ê·  Recall: 0.9768\n",
      "âœ… ì„±ê³µ ìš”ì²­ ìˆ˜: 10805ê°œ\n",
      "âš ï¸ ì‹¤íŒ¨ ìš”ì²­ ìˆ˜: 0ê°œ\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from itertools import cycle\n",
    "from prompts.template_format import format_prompt\n",
    "from optimizer.evaluator import compute_scores\n",
    "from openai import AsyncOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "import os\n",
    "\n",
    "# ğŸ§  ë¹„ë™ê¸° ì´ë²¤íŠ¸ ë£¨í”„ ì¶©ëŒ ë°©ì§€ (Jupyter ì „ìš©)\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()\n",
    "\n",
    "# ğŸ“¦ API í‚¤ ìµœëŒ€ 10ê°œ ë¡œë”©\n",
    "API_KEYS = [os.getenv(f\"UPSTAGE_API_KEY_{i}\") for i in range(1, 11)]\n",
    "API_KEYS = [k for k in API_KEYS if k]\n",
    "\n",
    "clients = [\n",
    "    AsyncOpenAI(api_key=key, base_url=\"https://api.upstage.ai/v1\")\n",
    "    for key in API_KEYS\n",
    "]\n",
    "client_cycle = cycle(clients)\n",
    "semaphores = {client: asyncio.Semaphore(3) for client in clients}  # í‚¤ë‹¹ ìµœëŒ€ ë™ì‹œ 3ê±´ ì œí•œ\n",
    "\n",
    "# ğŸ“„ í…œí”Œë¦¿ ë¡œë“œ\n",
    "graph_path = \"data/prompt_graph.jsonl\"\n",
    "selected_template_id = \"base_02\"\n",
    "with open(graph_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        if obj.get(\"id\") == selected_template_id:\n",
    "            template_str = obj[\"template\"]\n",
    "            break\n",
    "\n",
    "# ğŸ§ª ë°ì´í„° ë¡œë”©\n",
    "df = pd.read_csv(\"data/test_with_answer.csv\")\n",
    "sample = [\n",
    "    {\"input\": row[\"err_sentence\"], \"output\": row[\"cor_sentence\"]}\n",
    "    for _, row in df.iterrows()\n",
    "    if pd.notnull(row[\"err_sentence\"]) and pd.notnull(row[\"cor_sentence\"])\n",
    "]\n",
    "\n",
    "# ğŸš€ ì œí•œ í¬í•¨ëœ LLM í˜¸ì¶œ\n",
    "async def call_with_limit(client, messages, input_text):\n",
    "    async with semaphores[client]:\n",
    "        try:\n",
    "            response = await client.chat.completions.create(\n",
    "                model=\"solar-pro\",\n",
    "                messages=messages\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ API í˜¸ì¶œ ì˜¤ë¥˜: {e} â†’ ì…ë ¥ ë¬¸ì¥: {input_text[:50]}...\")\n",
    "            return \"[ERROR]\"\n",
    "\n",
    "# ğŸ“Š ì „ì²´ í‰ê°€ í•¨ìˆ˜\n",
    "async def evaluate_all_concurrent(batch_size=100):\n",
    "    results = []\n",
    "    success_count = 0\n",
    "    error_count = 0\n",
    "\n",
    "    async def worker(row):\n",
    "        nonlocal success_count, error_count\n",
    "        client = next(client_cycle)\n",
    "        messages = format_prompt(template_str, row[\"input\"])\n",
    "        pred = await call_with_limit(client, messages, row[\"input\"])\n",
    "        if pred == \"[ERROR]\":\n",
    "            error_count += 1\n",
    "        else:\n",
    "            success_count += 1\n",
    "        return {\"prediction\": pred, \"output\": row[\"output\"]}\n",
    "\n",
    "    for i in tqdm(range(0, len(sample), batch_size), desc=\"ğŸ” ì „ì²´ ì§„í–‰ ìƒí™©\"):\n",
    "        batch = sample[i:i+batch_size]\n",
    "        tasks = [worker(row) for row in batch]\n",
    "        batch_results = await asyncio.gather(*tasks)\n",
    "        results.extend(batch_results)\n",
    "\n",
    "    # ğŸ” ì ìˆ˜ ê³„ì‚°\n",
    "    recalls = []\n",
    "    for res in results:\n",
    "        _, recall, _ = compute_scores(res[\"prediction\"], res[\"output\"])\n",
    "        recalls.append(recall)\n",
    "\n",
    "    avg_recall = sum(recalls) / len(recalls) if recalls else 0.0\n",
    "    print(f\"\\nğŸ“Š [{selected_template_id}] í‰ê·  Recall: {round(avg_recall, 4)}\")\n",
    "    print(f\"âœ… ì„±ê³µ ìš”ì²­ ìˆ˜: {success_count}ê°œ\")\n",
    "    print(f\"âš ï¸ ì‹¤íŒ¨ ìš”ì²­ ìˆ˜: {error_count}ê°œ\")\n",
    "\n",
    "# â–¶ ì‹¤í–‰\n",
    "await evaluate_all_concurrent(batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74a59bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“¤ í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡ ì§„í–‰ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [31:17<00:00, 17.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ì˜ˆì¸¡ ì™„ë£Œ: 10870ê°œ ë¬¸ì¥ â†’ 'data/submission.csv' ì €ì¥ë¨\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from itertools import cycle\n",
    "from prompts.template_format import format_prompt\n",
    "from openai import AsyncOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "import os\n",
    "\n",
    "# ë¹„ë™ê¸° ë£¨í”„ ì ìš© (Jupyterìš©)\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()\n",
    "\n",
    "# API í‚¤ ë¡œë”©\n",
    "API_KEYS = [os.getenv(f\"UPSTAGE_API_KEY_{i}\") for i in range(1, 11)]\n",
    "API_KEYS = [k for k in API_KEYS if k]\n",
    "\n",
    "clients = [\n",
    "    AsyncOpenAI(api_key=key, base_url=\"https://api.upstage.ai/v1\")\n",
    "    for key in API_KEYS\n",
    "]\n",
    "client_cycle = cycle(clients)\n",
    "semaphores = {client: asyncio.Semaphore(3) for client in clients}  # í‚¤ë‹¹ ìµœëŒ€ ë™ì‹œ 3ê±´ ì œí•œ\n",
    "\n",
    "# í…œí”Œë¦¿ ë¡œë“œ\n",
    "graph_path = \"data/prompt_graph.jsonl\"\n",
    "selected_template_id = \"base_02\"\n",
    "with open(graph_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        if obj.get(\"id\") == selected_template_id:\n",
    "            template_str = obj[\"template\"]\n",
    "            break\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”©\n",
    "df = pd.read_csv(\"data/test.csv\")\n",
    "sample = [\n",
    "    {\"id\": row[\"id\"], \"input\": row[\"err_sentence\"]}\n",
    "    for _, row in df.iterrows()\n",
    "    if pd.notnull(row[\"err_sentence\"])\n",
    "]\n",
    "\n",
    "# LLM í˜¸ì¶œ\n",
    "async def call_with_limit(client, messages, input_text):\n",
    "    async with semaphores[client]:\n",
    "        try:\n",
    "            response = await client.chat.completions.create(\n",
    "                model=\"solar-pro\",\n",
    "                messages=messages\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ API í˜¸ì¶œ ì˜¤ë¥˜: {e} â†’ ì…ë ¥ ë¬¸ì¥: {input_text[:50]}...\")\n",
    "            return \"[ERROR]\"\n",
    "\n",
    "# ì˜ˆì¸¡ ë° ì €ì¥\n",
    "async def generate_submission(output_path=\"data/submission.csv\", batch_size=100):\n",
    "    results = []\n",
    "\n",
    "    async def worker(row):\n",
    "        client = next(client_cycle)\n",
    "        messages = format_prompt(template_str, row[\"input\"])\n",
    "        pred = await call_with_limit(client, messages, row[\"input\"])\n",
    "        return {\n",
    "            \"id\": row[\"id\"],\n",
    "            \"err_sentence\": row[\"input\"],\n",
    "            \"cor_sentence\": pred\n",
    "        }\n",
    "\n",
    "    for i in tqdm(range(0, len(sample), batch_size), desc=\"ğŸ“¤ í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡ ì§„í–‰ ì¤‘\"):\n",
    "        batch = sample[i:i+batch_size]\n",
    "        tasks = [worker(row) for row in batch]\n",
    "        batch_results = await asyncio.gather(*tasks)\n",
    "        results.extend(batch_results)\n",
    "\n",
    "    # ì €ì¥\n",
    "    submission_df = pd.DataFrame(results)\n",
    "    submission_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nâœ… ì˜ˆì¸¡ ì™„ë£Œ: {len(results)}ê°œ ë¬¸ì¥ â†’ '{output_path}' ì €ì¥ë¨\")\n",
    "\n",
    "# â–¶ ì‹¤í–‰\n",
    "await generate_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3c5c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
