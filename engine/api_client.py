# engine/api_client.py

import os
import asyncio
from itertools import cycle
from openai import AsyncOpenAI
from dotenv import load_dotenv

load_dotenv()

BASE_URL = "https://api.upstage.ai/v1"
MODEL = "solar-pro"

# ğŸ”‘ ìµœëŒ€ 10ê°œ API í‚¤ ë¡œë”©
API_KEYS = [os.getenv(f"UPSTAGE_API_KEY_{i}") for i in range(1, 11)]
API_KEYS = [key for key in API_KEYS if key]

# ğŸ” client + semaphore ìŒ ìƒì„±
clients = [
    (AsyncOpenAI(api_key=key, base_url=BASE_URL), asyncio.Semaphore(4))
    for key in API_KEYS
]

# â™»ï¸ ìˆœí™˜ì ìƒì„± (round-robin ë°©ì‹)
client_cycle = cycle(clients)

# âœ… ë‹¤ì¤‘ í‚¤ ê¸°ë°˜ LLM í˜¸ì¶œ í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€)
async def call_llm(messages: list, retries: int = 3, delay: float = 1.2) -> str:
    client, semaphore = next(client_cycle)  # ë‹¤ìŒ í´ë¼ì´ì–¸íŠ¸/ì„¸ë§ˆí¬ì–´ ê°€ì ¸ì˜¤ê¸°

    async with semaphore:
        for attempt in range(retries):
            try:
                response = await client.chat.completions.create(
                    model=MODEL,
                    messages=messages
                )
                return response.choices[0].message.content.strip()
            except Exception as e:
                if "429" in str(e):
                    await asyncio.sleep(delay * (attempt + 1))  # ì ì§„ì  ë”œë ˆì´
                else:
                    break

    return "[ERROR] í˜¸ì¶œ ì‹¤íŒ¨"
