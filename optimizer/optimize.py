import os
import time
import random
from dotenv import load_dotenv
import pandas as pd
from submission.config import ExperimentConfig
from submission.utils.metrics import evaluate_correction
from optimizer.base_templates import BASE_TEMPLATES
from optimizer.async_runner import AsyncExperimentRunner
from optimizer.template_rewriter import generate_child_prompts
from optimizer.prompt_validator import validate_template, count_tokens
from optimizer.reinforce_graph import ReinforceGraph

def compute_reward(node, strategy="f1_penalized"):
    recall = node['valid_recall'].get('recall', 0)
    precision = node['valid_recall'].get('precision', 0)
    token_penalty = 0.01 * count_tokens(node['template'])

    if strategy == "recall_only":
        return recall - token_penalty

    elif strategy == "precision_only":
        return precision - token_penalty

    elif strategy == "f1_penalized":
        if recall + precision == 0:
            f1 = 0
        else:
            f1 = 2 * recall * precision / (recall + precision)
        return f1 - token_penalty

    elif strategy == "recall_precision_avg":
        return 0.5 * (recall + precision) - token_penalty

    else:
        raise ValueError(f"Unknown reward strategy: {strategy}")


def soft_topk_selection(nodes, k, epsilon=0.3):
    """Top-k Ï§ë ÏùºÎ∂ÄÎäî ÎûúÎç§ ÌÉêÏÉâÏúºÎ°ú ÍµêÏ≤¥ (epsilon-greedy Î∞©Ïãù)"""
    sorted_nodes = sorted(nodes, key=compute_reward, reverse=True)
    selected = sorted_nodes[:k]
    if random.random() < epsilon:
        candidates = sorted_nodes[k:]
        if candidates:
            selected[-1] = random.choice(candidates)
    return selected

def deduplicate_templates(templates):
    seen = set()
    unique = []
    for t in templates:
        content = t["template"].strip()
        if content in seen or count_tokens(content) > 2000:
            continue
        seen.add(content)
        unique.append(t)
    return unique

def main_loop(max_generation=5, top_k=5, n_children=3, toy_size=100, reward_strategy="recall_only"):
    load_dotenv()
    api_key = os.getenv("UPSTAGE_API_KEY")
    if not api_key:
        raise ValueError("API ÌÇ§Í∞Ä .envÏóê ÏóÜÏäµÎãàÎã§.")

    data_dir = os.path.join(os.path.dirname(__file__), "..", "data")
    train = pd.read_csv(os.path.join(data_dir, "train.csv"))
    toy_data = train.sample(n=toy_size, random_state=42).reset_index(drop=True)
    train_data = toy_data.sample(frac=0.8, random_state=42)
    valid_data = toy_data.drop(train_data.index)

    graph = ReinforceGraph()
    runner_cls = AsyncExperimentRunner

    if len(graph.load_all()) == 0:
        print("[Init] Ï¥àÍ∏∞ ÌÖúÌîåÎ¶ø Îì±Î°ù")
        graph.append_nodes(BASE_TEMPLATES)

    best_score_history = []
    patience = 3

    for gen in range(max_generation):
        print(f"\n=== [GENERATION {gen}] ===")
        current_gen = graph.get_generation(gen)
        evaluated_nodes = []

        for node in current_gen:
            config = ExperimentConfig(template_name=node["id"])
            runner = runner_cls(config, api_key, node["template"])
            result = runner.run_template_experiment(train_data, valid_data)
            node["train_recall"] = result["train_recall"]
            node["valid_recall"] = result["valid_recall"]
            evaluated_nodes.append(node)

        graph.append_nodes(evaluated_nodes)

        # ÏÑ±Îä• ÏöîÏïΩ
        rewards = [compute_reward(n, strategy=reward_strategy) for n in evaluated_nodes]
        best = max(rewards)
        avg = sum(rewards) / len(rewards)
        print(f"[GEN {gen}] ÌèâÍ∑† reward: {avg:.2f}, ÏµúÍ≥† reward: {best:.2f}")
        best_score_history.append(best)

        # Ï°∞Í∏∞ Ï¢ÖÎ£å (ÏÑ±Îä• Ï†ïÏ≤¥ Í∞êÏßÄ)
        if gen >= patience and all(
            best_score_history[-1] <= best_score_history[-1 - i]
            for i in range(1, patience + 1)
        ):
            print("üîö ÏÑ±Îä• Í∞úÏÑ† Ï†ïÏ≤¥Î°ú Ï°∞Í∏∞ Ï¢ÖÎ£åÌï©ÎãàÎã§.")
            break

        # Îã§Ïùå ÏÑ∏ÎåÄ ÏûêÏãù ÏÉùÏÑ±
        topk = soft_topk_selection(evaluated_nodes, top_k, epsilon=0.3)
        children = generate_child_prompts(topk, n_children, api_key)
        filtered = [
            c for c in deduplicate_templates(children) if validate_template(c["template"])
        ]
        print(f"[GEN {gen+1}] Ïú†Ìö®Ìïú ÏûêÏãù Ïàò: {len(filtered)}Í∞ú")
        graph.append_nodes(filtered)

        if not filtered:
            print("‚ö†Ô∏è Ïú†Ìö®Ìïú ÏûêÏãù ÌÖúÌîåÎ¶øÏù¥ ÏóÜÏñ¥ Ï¢ÖÎ£åÌï©ÎãàÎã§.")
            break

if __name__ == "__main__":
    main_loop(
        max_generation=3,       # Î£®ÌîÑ 3ÏÑ∏ÎåÄ
        top_k=3,                # ÏÉÅÏúÑ 3Í∞ú ÏÑ†ÌÉù
        n_children=3,           # ÏûêÏãù 3Í∞úÏî© ÏÉùÏÑ±
        toy_size=30,            # ÌèâÍ∞ÄÏö© ÏÉòÌîå 30Í∞ú
        reward_strategy="f1_penalized"  # Î≥µÌï© Ï†êÏàò ÌôúÏö©
    )